{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c6ff6f-72b4-44e2-ac59-d099a1cdfe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import mediapipe as mp\n",
    "from picamera2 import Picamera2\n",
    "import time\n",
    "import copy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e77653-d77b-4502-92d5-126b179740fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e0c723-2dc4-4cc3-8873-524b4898262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('Gesture_Data') \n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['hello', 'please', 'thanks', 'receipt', 'more', 'price', 'order', 'wait', 'bag', 'water','0', '1', '2', '3', '4', '5', '(6W)', '7', '8', '(9F)', 'a', 'b', 'c', 'd', 'e', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z'])\n",
    "\n",
    "# numer of sequences to capture\n",
    "no_sequences = 45\n",
    "\n",
    "# Videos are going to be 15 frames in length\n",
    "sequence_length = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c1948",
   "metadata": {},
   "source": [
    "Creating Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ce4a6-9647-4446-b748-79bdbdbd94d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the base directory exists\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "    \n",
    "for action in actions:\n",
    "    # Ensure the action folder exists\n",
    "    action_path = os.path.join(DATA_PATH, action)\n",
    "    if not os.path.exists(action_path):\n",
    "        os.makedirs(action_path)\n",
    "    \n",
    "    # Find the maximum existing directory index\n",
    "    dirmax = 0\n",
    "    existing_dirs = os.listdir(action_path)\n",
    "    if existing_dirs:\n",
    "        dirmax = np.max(np.array(existing_dirs).astype(int))\n",
    "    \n",
    "    # print(f\"Current dirmax for {action}: {dirmax}\")\n",
    "    \n",
    "    # Create new folders starting from 0\n",
    "    for sequence in range(no_sequences):  # Should start from 0\n",
    "        folder_name = str(dirmax + sequence)  # Sequence starts at dirmax (which is usually 0)\n",
    "        folder_path = os.path.join(action_path, folder_name)\n",
    "        \n",
    "        try:\n",
    "            os.makedirs(folder_path)\n",
    "            print(f\"Created folder: {folder_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating folder {folder_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d94887-8c4d-40aa-bb71-212defcc3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "picam2 = Picamera2()\n",
    "picam2.configure(picam2.create_preview_configuration(main={\"format\": \"RGB888\", \"size\": (480,640)}))\n",
    "picam2.start()\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471e2055-658f-4d95-a652-e9f95e9cf3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(frame, results):\n",
    "    # Draw multi hand landmarks\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                None,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909e23ee",
   "metadata": {},
   "source": [
    "Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87e8940c-9020-4509-84df-5f9755fe07bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1],image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    for _,landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        landmark_z = landmark.z\n",
    "        landmark_point.append([landmark_x, landmark_y, landmark_z])\n",
    "\n",
    "    return landmark_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "615b78b7-c4da-4aae-8f92-8d72b1c612a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_landmarks(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    base_x, base_y = 0,0\n",
    "\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y, base_z = landmark_point[0], landmark_point[1], landmark_point[2]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "        temp_landmark_list[index][2] = temp_landmark_list[index][2] - base_z\n",
    "\n",
    "    temp_landmark_list = list(itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    max_value = max(list(map(abs,temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf1485-d1b6-4691-a00d-e6624f70ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(frame, results):\n",
    "\n",
    "    processed_hands = {\"Right\": None, \"Left\" : None}\n",
    "    \n",
    "    if results.multi_hand_landmarks and results.multi_handedness:\n",
    "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "            hand_label = handedness.classification[0].label\n",
    "    \n",
    "            landmark_list = gather_landmark_list(frame, hand_landmarks)\n",
    "    \n",
    "            processed_landmarks = pre_process_landmarks(landmark_list)\n",
    "    \n",
    "            processed_hands[hand_label] = processed_landmarks\n",
    "\n",
    "    if processed_hands[\"Right\"] is None:\n",
    "        processed_hands[\"Right\"] = [0] * (21*3)\n",
    "    if processed_hands[\"Left\"] is None:\n",
    "        processed_hands[\"Left\"] = [0] * (21*3)\n",
    "    \n",
    "    return np.array(processed_hands[\"Right\"] + processed_hands[\"Left\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367ed5e6",
   "metadata": {},
   "source": [
    "Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dedf7f2-b1b4-414e-b979-211cdac237d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set mediapipe configurations and collect data\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    collecting = False\n",
    "    running = True\n",
    "    while running:\n",
    "        # Capture frame\n",
    "        frame = picam2.capture_array()\n",
    "        frame = cv.flip(frame, -1)\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        frame = cv.rotate(frame, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "        # Get frame dimensions\n",
    "        height, width, _ = frame.shape\n",
    "    \n",
    "        # Apply zoom (center crop)\n",
    "        zoom_factor = 1.5\n",
    "        new_width = int(width / zoom_factor)\n",
    "        new_height = int(height / zoom_factor)\n",
    "        x_start = (width - new_width) // 2\n",
    "        y_start = (height - new_height) // 2\n",
    "        cropped_frame = frame[y_start:y_start+new_height, x_start:x_start+new_width]\n",
    "    \n",
    "        # Resize back to 480x640\n",
    "        zoomed_frame = cv.resize(cropped_frame, (width, height), interpolation=cv.INTER_LINEAR)\n",
    "\n",
    "        # Process\n",
    "        results = hands.process(zoomed_frame)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_landmarks(zoomed_frame, results)\n",
    "        \n",
    "        # Display instructions\n",
    "        if not collecting:\n",
    "            cv.putText(zoomed_frame, 'Press \"=\" to start collecting data', (15, 30),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2, cv.LINE_AA)\n",
    "        else:\n",
    "            cv.putText(zoomed_frame, 'Collecting frames...', (15, 30),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv.imshow('OpenCV Feed', zoomed_frame)\n",
    "        \n",
    "        # Check for user input\n",
    "        key = cv.waitKey(10) & 0xFF\n",
    "        \n",
    "        # Start collection if '=' is pressed\n",
    "        if key == 61:  # ASCII code for '=' key\n",
    "            collecting = True\n",
    "            print(\"Started collecting data\")\n",
    "            \n",
    "        # Exit if 'ESC' is pressed\n",
    "        if key == 27:  # ASCII code for 'ESC'\n",
    "            running = False\n",
    "            break\n",
    "\n",
    "        # Start collection logic\n",
    "        if collecting:\n",
    "            # Loop through actions\n",
    "            for action in actions:\n",
    "                for sequence in range(no_sequences):\n",
    "                    for frame_num in range(sequence_length):\n",
    "\n",
    "                        # Capture frame\n",
    "                        frame = picam2.capture_array()\n",
    "                        frame = cv.flip(frame, -1)\n",
    "                        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "                        frame = cv.rotate(frame, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "                        # Get frame dimensions\n",
    "                        height, width, _ = frame.shape\n",
    "                    \n",
    "                        # Apply zoom (center crop)\n",
    "                        zoom_factor = 1.5\n",
    "                        new_width = int(width / zoom_factor)\n",
    "                        new_height = int(height / zoom_factor)\n",
    "                        x_start = (width - new_width) // 2\n",
    "                        y_start = (height - new_height) // 2\n",
    "                        cropped_frame = frame[y_start:y_start+new_height, x_start:x_start+new_width]\n",
    "                    \n",
    "                        # Resize back to 480x640\n",
    "                        zoomed_frame = cv.resize(cropped_frame, (width, height), interpolation=cv.INTER_LINEAR)\n",
    "\n",
    "                        # Process\n",
    "                        results = hands.process(zoomed_frame)\n",
    "                        \n",
    "                        # Draw landmarks\n",
    "                        draw_landmarks(zoomed_frame, results)\n",
    "                        \n",
    "                        # Display collection info\n",
    "                        if frame_num == 0: \n",
    "                            cv.putText(zoomed_frame, 'STARTING COLLECTION', (120, 200), \n",
    "                                       cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 1, cv.LINE_AA)\n",
    "                            cv.putText(zoomed_frame, f'Collecting frames for {action} Video Number {sequence}', (15, 12), \n",
    "                                       cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1, cv.LINE_AA)\n",
    "                            cv.imshow('OpenCV Feed', zoomed_frame)\n",
    "                            cv.waitKey(2000)\n",
    "                        else: \n",
    "                            cv.putText(zoomed_frame, f'Collecting frames for {action} Video Number {sequence}', (15, 12), \n",
    "                                       cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv.LINE_AA)\n",
    "                            cv.imshow('OpenCV Feed', zoomed_frame)\n",
    "                        \n",
    "                        # Export keypoints if needed\n",
    "                        keypoints = extract_keypoints(zoomed_frame, results)\n",
    "                        npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                        np.save(npy_path, keypoints)\n",
    "                        \n",
    "                        # Check for 'ESC' key to stop collection\n",
    "                        if cv.waitKey(10) & 0xFF == 27:\n",
    "                            running = False\n",
    "                            break\n",
    "                        \n",
    "                    if not running:\n",
    "                        break\n",
    "                if not running:\n",
    "                    break\n",
    "            \n",
    "            # End collection\n",
    "            collecting = False\n",
    "        \n",
    "    cv.destroyAllWindows()\n",
    "    picam2.stop()\n",
    "    picam2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352471bd",
   "metadata": {},
   "source": [
    "Making dataset and labelset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e26eb22d-3204-4949-80e0-e4245bee58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "signs = np.array(['hello', 'please', 'thanks', 'receipt', 'more', 'price', 'order', 'wait', 'bag', 'water','0', '1', '2', '3', '4', '5', '(6W)', '7', '8', '(9F)', 'a', 'b', 'c', 'd', 'e', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea77f0b8-185c-4b06-808a-f497408021e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(signs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98bd195-2c11-484c-9033-cb8c4e794533",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c0e64d8-f97a-4644-9859-8725ba059985",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for sign in signs:\n",
    "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH, sign))).astype(int):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, sign, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[sign])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94249f1e-62cb-4f59-895a-6ba3724881a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('sequences.npy', np.array(sequences))\n",
    "np.save('labels.npy', np.array(labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
